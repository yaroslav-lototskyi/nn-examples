{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# ===================== 1. PARAMETERS =====================\n",
    "batch_size = 128       # Batch size\n",
    "latent_dim = 100       # Size of the noise vector\n",
    "image_size = 28        # MNIST image size\n",
    "epochs = 10            # Number of epochs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "\n",
    "# ===================== 2. LOAD DATA =====================\n",
    "# Transform: convert to tensor and normalize to [-1, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# ===================== 3. MODEL ARCHITECTURES =====================\n",
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 128, 7, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 1, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()  # Output in the range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 7 * 7, 1),\n",
    "            nn.Sigmoid()  # Output probability of being real\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# ===================== 4. INITIALIZATION =====================\n",
    "# Initialize models\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Loss function and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Fixed noise for monitoring progress\n",
    "fixed_noise = torch.randn(64, latent_dim, 1, 1, device=device)\n",
    "\n",
    "# Create a folder to save results\n",
    "os.makedirs(\"mnist_gan_results\", exist_ok=True)\n",
    "\n",
    "# ===================== 5. TRAINING GAN =====================\n",
    "# List to store generated images at each epoch\n",
    "generated_images = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (real_imgs, _) in enumerate(train_loader):\n",
    "        # Prepare real and fake labels\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        real_labels = torch.full((real_imgs.size(0), 1), 0.9, device=device)  # Label smoothing\n",
    "        fake_labels = torch.zeros(real_imgs.size(0), 1, device=device)\n",
    "\n",
    "        # === Train the Discriminator ===\n",
    "        optimizer_D.zero_grad()\n",
    "        noise = torch.randn(real_imgs.size(0), latent_dim, 1, 1, device=device)\n",
    "        fake_imgs = generator(noise)\n",
    "        \n",
    "        # Loss for real and fake images\n",
    "        real_loss = criterion(discriminator(real_imgs), real_labels)\n",
    "        fake_loss = criterion(discriminator(fake_imgs.detach()), fake_labels)\n",
    "        d_loss = real_loss + fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # === Train the Generator ===\n",
    "        optimizer_G.zero_grad()\n",
    "        fake_labels.fill_(1)  # Generator aims to \"fool\" the discriminator\n",
    "        g_loss = criterion(discriminator(fake_imgs), fake_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    # Print losses for monitoring\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n",
    "    \n",
    "    # Generate and save images for this epoch\n",
    "    with torch.no_grad():\n",
    "        fake_imgs = generator(fixed_noise).detach().cpu()\n",
    "        generated_images.append(fake_imgs)  # Store for visualization\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# ===================== 6. VISUALIZATION =====================\n",
    "# Combine generated images into a grid with labels for each epoch\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))  # 2x5 grid for 10 epochs\n",
    "fig.suptitle(\"Generated Images Across Epochs\", fontsize=16)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img_grid = vutils.make_grid(generated_images[i], nrow=8, normalize=True)\n",
    "    ax.imshow(img_grid.permute(1, 2, 0))  # Convert to HWC format\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"Epoch {i+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
